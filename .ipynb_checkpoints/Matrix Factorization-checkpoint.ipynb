{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * (reg * Ui - Yij * Vj + Ui.dot(Vj) * Vj)\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * (reg * Vj - Yij * Ui + Ui.dot(Vj) * Ui)\n",
    "\n",
    "def grad_bias(Vj, Yij, Ui, eta, ai, bj):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate), and bias entries ai, bj.\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to bias multiplied by learning rate.\n",
    "    \"\"\"\n",
    "    return -eta * (Yij - (Ui.dot(Vj) + ai + bj))\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    sum_u = np.linalg.norm(U, ord = 'fro') ** 2\n",
    "    sum_v = np.linalg.norm(V, ord = 'fro') ** 2\n",
    "    sum_err = 0\n",
    "    for i, j, rating in Y:\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "        sum_err += (rating - U[i, :].T.dot(V[j, :])) ** 2\n",
    "    return reg / 2 * (sum_u + sum_v) + sum_err / 2\n",
    "\n",
    "def get_err_bias(U, V, Y, a, b, reg = 0.0):\n",
    "    sum_u = np.linalg.norm(U, ord = 'fro') ** 2\n",
    "    sum_v = np.linalg.norm(V, ord = 'fro') ** 2\n",
    "    sum_err = 0\n",
    "    for i, j, rating in Y:\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "        sum_err += (rating - U[i, :].T.dot(V[j, :]) - a[i] - b[j]) ** 2\n",
    "    return reg / 2 * (sum_u + sum_v) + sum_err / 2\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300, bias = False):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    U = np.random.uniform(-0.5, 0.5, size = (M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, size = (N, K))\n",
    "    if bias:\n",
    "        a = np.random.uniform(-0.5, 0.5, size = (M, ))\n",
    "        b = np.random.uniform(-0.5, 0.5, size = (N, ))\n",
    "    first_reduction = 0\n",
    "    for k in range(max_epochs):\n",
    "        if bias:\n",
    "            curr_err = get_err_bias(U, V, Y, a, b, reg)\n",
    "        else:\n",
    "            curr_err = get_err(U, V, Y, reg)\n",
    "        for i, j, rating in np.random.permutation(Y):\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "            Ui = np.copy(U[i, :])\n",
    "            Vj = np.copy(V[j, :])\n",
    "            U[i, :] -= grad_U(Ui, rating, Vj, reg, eta)\n",
    "            V[j, :] -= grad_V(Vj, rating, Ui, reg, eta)\n",
    "            if bias:\n",
    "                ai = a[i]\n",
    "                bj = b[j]\n",
    "                change = grad_bias(Vj, rating, Ui, eta, ai, bj)\n",
    "                a[i] -= change\n",
    "                b[j] -= change\n",
    "        if bias:\n",
    "            next_err = get_err_bias(U, V, Y, a, b, reg)\n",
    "        else:\n",
    "            next_err = get_err(U, V, Y, reg)\n",
    "        if k == 0:\n",
    "            first_reduction = curr_err - next_err\n",
    "        else:\n",
    "            if (curr_err - next_err) / first_reduction <= eps:\n",
    "                break\n",
    "    if bias:\n",
    "        return (U, V, next_err, a, b)\n",
    "    else:\n",
    "        return (U, V, next_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with  943  users,  1682  movies.\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.loadtxt('data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('data/test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "K = 20\n",
    "\n",
    "reg = 0.0\n",
    "eta = 0.03 # learning rate\n",
    "\n",
    "U,V, err = train_model(M, N, K, eta, reg, Y_train)\n",
    "E_in_no_bias = err\n",
    "E_out_no_bias = get_err(U, V, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17944.469196887014\n",
      "5904.652273565599\n"
     ]
    }
   ],
   "source": [
    "print(E_in_no_bias)\n",
    "print(E_out_no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, V, err, a, b = train_model(M, N, K, eta, reg, Y_train, bias = True)\n",
    "E_in_bias = err\n",
    "E_out_bias = get_err_bias(U, V, Y_test, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20619.96676035208\n",
      "5831.907188074287\n"
     ]
    }
   ],
   "source": [
    "print(E_in_bias)\n",
    "print(E_out_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
